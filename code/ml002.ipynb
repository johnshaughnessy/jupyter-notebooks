{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d486320-a9fb-4430-adfb-559037a55fa4",
   "metadata": {},
   "source": [
    "This notebook implements gradient descent for linear regression over a single feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed67db-3c18-45db-9a6c-73aaf3e7590c",
   "metadata": {},
   "source": [
    "First, we'll generate data points along some line, with random noise causing the points to be above or below the line.\n",
    "Our goal will be to use linear regression to recover the original line, using only the (noisy) data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a4e9e1-03c7-45bf-9fd8-8da4aa7f4c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "original_w = 2.5\n",
    "original_b = 20\n",
    "x = []\n",
    "y = []\n",
    "for x_i in list(range(100)):\n",
    "    noise = (random.random()-0.5)*10\n",
    "    x.append(x_i)\n",
    "    y.append(original_w * x_i + original_b + noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbdc8b13-2e3a-4e59-9ec7-13962551e186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[15.630057646259187, 24.961768953166466, 29.86405035279268, 27.641313564634522, 29.076205576826563]\n"
     ]
    }
   ],
   "source": [
    "print(x[0:5])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e400b-db3f-4525-bf36-ef42f598a887",
   "metadata": {},
   "source": [
    "We'll need a cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3640534c-1e62-4e24-92b8-57a71246a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(x, y, w, b):\n",
    "    cost = 0\n",
    "    m = len(x)\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb = (w*x[i] + b)\n",
    "        cost += (f_wb - y[i])**2\n",
    "\n",
    "    cost = cost * (1 / (2*m))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c41879-ed14-40c1-89bf-3bb8a0a1348a",
   "metadata": {},
   "source": [
    "The cost won't be exactly zero, even with our original weight and bias, because we added noise to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7032f5-a9da-428b-accb-0ba0db236a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6850773669781196"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cost(x, y, original_w, original_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4387da-377d-4f54-9e2b-8d6211c11b90",
   "metadata": {},
   "source": [
    "But, we expect the cost to (usually) be lower than it is for other values of w and b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381a2784-7f02-41c1-b450-9c083e1db1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386.048925937017\n",
      "199.05152628165766\n",
      "1052.895301430438\n",
      "\n",
      "1121.3226067843816\n",
      "70.27322266145595\n",
      "750.5512795849261\n",
      "\n",
      "3.8987296986933457\n",
      "7.363463815970462\n",
      "6.514978479913101\n"
     ]
    }
   ],
   "source": [
    "print(calculate_cost(x,y, original_w + random.random(), original_b + random.random()*10))\n",
    "print(calculate_cost(x,y, original_w + random.random(), original_b + random.random()*10))\n",
    "print(calculate_cost(x,y, original_w + random.random(), original_b + random.random()*10))\n",
    "print()\n",
    "print(calculate_cost(x,y, original_w + random.random(), original_b))\n",
    "print(calculate_cost(x,y, original_w + random.random(), original_b))\n",
    "print(calculate_cost(x,y, original_w + random.random(), original_b))\n",
    "print()\n",
    "print(calculate_cost(x,y, original_w, original_b + random.random()*10))\n",
    "print(calculate_cost(x,y, original_w, original_b + random.random()*10))\n",
    "print(calculate_cost(x,y, original_w, original_b + random.random()*10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539d0ecb-f33f-4810-9b24-896487073ecf",
   "metadata": {},
   "source": [
    "When we implement gradient descent, we'll initialize `w` and `b` to some random numbers and then iteratively update them. We'll update each in the direction that minimized the cost function `J`. In order to figure out how to change `w` and `b` to minimize the cost function, we need to know the partial of `J` w.r.t. `w` and the partial of `J` w.r.t. `b`. Together, we call these partials the gradient.\n",
    "\n",
    "Here is a reminder about how to calculate the partial of `J` w.r.t. `w`:\n",
    "- `J` is a function of `f`, `x` and `y`.\n",
    "- So the partial of `J` w.r.t. `w` is: `(dJ/df)*(df/dw) + (dJ/dx)*(dx/dw) + (dJ/dy)*(dy/dw)`.\n",
    "- The partials `(dx/dw)` and `(dy/dw)` are both equal to zero, so we can focus on the first part: `(dJ/df)*(df/dw)`.\n",
    "- `J` is `(1/(2*m))*sum( (f(x_i) - y_i)**2 )` or (when we expand the squared term) `(1/(2*m))*sum( f(x_i)**2 - 2*f(x_i)*y_i + y_i**2 )`\n",
    "- To make it easier to read, we might write this as:\n",
    "- Then, `J = (1/2m)*sum( f**2 - 2fy + y**2 )`\n",
    "- So `dJ/df` is `(1/2m)*sum( 2f - 2y + 0)` or `(1/m)*sum(f - y)`\n",
    "- `f` is `wx + b`\n",
    "- So `df/dw` is `x`.\n",
    "- Putting this all together, we have:\n",
    "\n",
    "```python\n",
    "(dJ/dw)\n",
    "    = (dJ/df)*(df/dw) + (dJ/dx)*(dx/dw) + (dJ/dy)*(dy/dw)\n",
    "    = (dJ/df)*(df/dw) + 0               + 0\n",
    "    = (dJ/df)*(df/dw)\n",
    "    = ((1/m)*sum(f - y)) * x\n",
    "    = ((1/m)*sum((f(x_i) - y_i)*x_i)\n",
    "```\n",
    "\n",
    "The derivation of `(dJ/db)` is the same, except that `(df/db)` is `1` (whereas `(df/dw)` was `x`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89336713-7535-4772-84d8-61257f8e593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(x,y,w,b):\n",
    "    dJdw = 0\n",
    "    dJdb = 0\n",
    "    for i in range(len(x)):\n",
    "        f = w*x[i] + b\n",
    "        dJdw = (f - y[i])*x[i]\n",
    "        dJdb = (f - y[i])\n",
    "    dJdw = dJdw * (1.0/len(x))\n",
    "    dJdb /= len(x)\n",
    "    return dJdw, dJdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb5ea29-8aa1-4c70-9db4-5045d7e4300f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.1618381621009726, 0.03193775921314113)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_gradient(x, y, original_w, original_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f10b1-208b-4012-9bc4-06fc685efd3a",
   "metadata": {},
   "source": [
    "Now that we can calculate gradients, we can implement gradient descent.\n",
    "\n",
    "The way this will work is that we'll start with a random w and b, and then update them by the learning rate times their partial derivatives. There are many ways we might choose to stop, but let's try taking 100 steps and seeing how much we can minimize the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ce0ad9-9107-4f84-a7a0-50362c1bfb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, learn_rate, steps):\n",
    "    w = w_in\n",
    "    b = b_in\n",
    "    for _ in range(steps):\n",
    "        dJdw, dJdb = calculate_gradient(x,y,w,b)\n",
    "        # print(\"dJdb is\", dJdb)\n",
    "        # print(\"dJdw is\", dJdw)\n",
    "        w -= learn_rate*dJdw\n",
    "        b -= learn_rate*dJdb\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7dceb2-0f5f-4209-9938-41ab09a0793a",
   "metadata": {},
   "source": [
    "Now, let's see if this process minimizes our cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e40fbadb-27e3-4e9f-878e-7ef41abc86a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_w = -32.070543\n",
      "random_b = 7.502585\n"
     ]
    }
   ],
   "source": [
    "random_w = (random.random()-0.5)*100\n",
    "random_b = (random.random()-0.5)*100\n",
    "print(f\"random_w = {random_w:2f}\\nrandom_b = {random_b:2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc004c6a-1674-4d50-898c-802cdc5ddedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_w = -32.070543\n",
      "initial_b = 7.502585\n",
      "final_w = 2.588531\n",
      "final_b = 7.852676\n",
      "goal_w = 2.500000\n",
      "goal_b = 20.000000\n",
      "[1630819.9728555079, 1341156.9342931022, 1103010.0419689855, 907211.0826311165, 746224.0639972285, 613854.5760372402, 505010.9093758642, 415507.71340688574, 341904.6182796631, 281373.5941290614, 231589.92984084346, 190642.62507060665, 156960.73833912573, 129252.84971945937, 106457.30267181447, 87701.30549963967, 72267.31474539892, 59565.40380904253, 49110.5509989296, 40503.971025410494, 33417.76994586979, 27582.331786717805, 22775.950450416934, 18816.307130765304, 15553.464649707967, 12864.108641008896, 10646.813598052706, 8818.151330597642, 7309.491863708191, 6064.373514965031, 5036.340833721688, 4187.167125498669, 3485.393111602818, 2905.125460802729, 2425.0489465679325, 2027.6142164424782, 1698.3699272000633, 1425.413561580352, 1198.9398142037983, 1010.8691920623577, 854.5425637367225, 724.4699303337491, 616.123777991089, 525.7690871425472, 450.32348372728126, 387.2421765291845, 334.42327753789834, 290.1298853600913, 252.92595546898326, 221.6235102754771, 195.23917703106116, 172.95839919474335, 154.10596089254523, 138.12170579420723, 124.54053043634119, 112.97589538650024, 103.1062319573043, 94.66373261398847, 87.42510402150072, 81.20393634167172, 75.8444037879979, 71.21606193540453, 67.20954880486217, 63.73303089279084, 60.70926340357538, 58.073157048076, 55.7697627774211, 53.75260145810908, 51.98227836010827, 50.425332916522514, 49.05328292611869, 47.84182954137216, 46.77019528814821, 45.8205722237221, 44.9776613424293, 44.2282876349606, 43.5610779232006, 42.96619083044178, 42.43509009137378, 41.96035392697171, 41.53551446362355, 41.154922210489104, 40.8136314630262, 40.507303205619, 40.23212266862072, 39.984729176319036, 39.762156320297066, 39.561780821795104, 39.381278719242744, 39.21858774284929, 39.07187492528218, 38.9395086527334, 38.82003448962391, 38.71215421732011, 38.614707616420546, 38.52665659643763, 38.44707133859762, 38.37511816921681, 38.3100489243077, 38.25119160228231]\n"
     ]
    }
   ],
   "source": [
    "w = random_w\n",
    "b = random_b\n",
    "print(f\"initial_w = {w:2f}\\ninitial_b = {b:2f}\")\n",
    "costs = []\n",
    "for _ in range(100):\n",
    "    w,b = gradient_descent(x,y,w,b,1e-5, 100)\n",
    "    costs.append(calculate_cost(x,y,w,b))\n",
    "\n",
    "print(f\"final_w = {w:2f}\\nfinal_b = {b:2f}\")\n",
    "print(f\"goal_w = {original_w:2f}\\ngoal_b = {original_b:2f}\")\n",
    "print(costs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da815a9f-2ab8-4d20-aadf-fd3448d66317",
   "metadata": {},
   "source": [
    "The `w` and `b` we found isn't as good as our `original_w` and `original_b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cee4cf4-c62b-4ff5-a4ff-e63fa2bbc5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6850773669781196"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cost(x, y, original_w, original_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6169ad4-9a2d-4b0a-bcf3-8b86928cd1ca",
   "metadata": {},
   "source": [
    "But it might perform better with additional training data. Let's give it 10000 points to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cad09cd5-5319-4d51-abd5-dcf29554b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_w = 2.5\n",
    "original_b = 20\n",
    "x = []\n",
    "y = []\n",
    "for x_i in list(range(10000)):\n",
    "    noise = (random.random()-0.5)*10\n",
    "    x.append(x_i)\n",
    "    y.append(original_w * x_i + original_b + noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3656f18-b723-4de1-9716-3fe0c0b3691e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_w = -32.070543\n",
      "initial_b = 7.502585\n",
      "final_w = 2.501474\n",
      "final_b = 7.506042\n",
      "goal_w = 2.500000\n",
      "goal_b = 20.000000\n",
      "[52.9174710867869, 26.44129195286023, 26.44096286848585, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787, 26.440962859752787]\n"
     ]
    }
   ],
   "source": [
    "# For a fair test, we'll use the same randomly chosen w and b from before.\n",
    "w = random_w\n",
    "b = random_b\n",
    "print(f\"initial_w = {w:2f}\\ninitial_b = {b:2f}\")\n",
    "costs = []\n",
    "for _ in range(100):\n",
    "    w,b = gradient_descent(x,y,w,b,1e-5, 100)\n",
    "    costs.append(calculate_cost(x,y,w,b))\n",
    "\n",
    "print(f\"final_w = {w:2f}\\nfinal_b = {b:2f}\")\n",
    "print(f\"goal_w = {original_w:2f}\\ngoal_b = {original_b:2f}\")\n",
    "print(costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d9d2c2-fa07-495d-ab1b-f8820b48b126",
   "metadata": {},
   "source": [
    "Finally we'll do one more test with 100000 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f286ea1-ca09-4d43-ae95-a0a4dae3310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_w = 2.5\n",
    "original_b = 20\n",
    "x = []\n",
    "y = []\n",
    "for x_i in list(range(100000)):\n",
    "    noise = (random.random()-0.5)*10\n",
    "    x.append(x_i)\n",
    "    y.append(original_w * x_i + original_b + noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "903a23a5-1c6d-4cbd-b473-a11e754aea3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_w = -32.070543\n",
      "initial_b = 7.502585\n",
      "final_w = 2.500150\n",
      "final_b = 7.502930\n",
      "goal_w = 2.500000\n",
      "goal_b = 20.000000\n",
      "[25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246, 25.965231357189246]\n"
     ]
    }
   ],
   "source": [
    "# For a fair test, we'll use the same randomly chosen w and b from before.\n",
    "w = random_w\n",
    "b = random_b\n",
    "print(f\"initial_w = {w:2f}\\ninitial_b = {b:2f}\")\n",
    "costs = []\n",
    "for _ in range(100):\n",
    "    w,b = gradient_descent(x,y,w,b,1e-5, 100)\n",
    "    costs.append(calculate_cost(x,y,w,b))\n",
    "\n",
    "print(f\"final_w = {w:2f}\\nfinal_b = {b:2f}\")\n",
    "print(f\"goal_w = {original_w:2f}\\ngoal_b = {original_b:2f}\")\n",
    "print(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2cbecb-ea8a-434f-8223-ca0a6915b062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
